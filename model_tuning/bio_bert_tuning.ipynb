{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, get_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/working/ML_week_SA_drugs/data/drug_review_train.csv\")\n",
    "df_test = pd.read_csv(\"/kaggle/working/ML_week_SA_drugs/data/drug_review_validation.csv\")\n",
    "### mapping ratings to sentiment categories\n",
    "def map_rating_to_sentiment(rating):\n",
    "    if 8 <= rating <= 10:\n",
    "        return 'positive'\n",
    "    elif 5 <= rating <= 7:\n",
    "        return 'neutral'\n",
    "    elif 1 <= rating <= 4:\n",
    "        return 'negative'\n",
    "\n",
    "\n",
    "df['rating_category'] = df['rating'].apply(map_rating_to_sentiment)\n",
    "df_test['rating_category'] = df_test['rating'].apply(map_rating_to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/kaggle/input/biobert-084\" \n",
    "\n",
    "best_learning_rate = 1.0935406790014464e-05 \n",
    "best_num_epochs = 9 \n",
    "best_batch_size = 8\n",
    "# Map sentiments to numeric values\n",
    "label_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
    "df[\"rating_category\"] = df[\"rating_category\"].map(label_mapping)\n",
    "df_test[\"rating_category\"] = df_test[\"rating_category\"].map(label_mapping)\n",
    "# Extract test data\n",
    "X_full = df[\"review\"]\n",
    "y_full = df[\"rating_category\"]\n",
    "X_test = df_test[\"review\"]\n",
    "y_test = df_test[\"rating_category\"]\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Function to Tokenize Text\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Tokenize training data\n",
    "train_encodings = tokenize_function(X_full.tolist())\n",
    "\n",
    "# Tokenize test data\n",
    "test_encodings = tokenize_function(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: val.numpy() for key, val in encodings.items()}\n",
    "        self.labels = labels.reset_index(drop=True).astype(int).to_numpy()\n",
    "\n",
    "        # Ensure dataset sizes match\n",
    "        self.size = min(len(self.encodings[\"input_ids\"]), len(self.labels))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.size:  # Prevent out-of-bounds errors\n",
    "            raise IndexError(f\"Index {idx} out of bounds for dataset of size {self.size}\")\n",
    "\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size  # Use the minimum size to prevent mismatches\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_encodings, y_full)\n",
    "test_dataset = SentimentDataset(test_encodings, y_test)\n",
    "\n",
    "# ===================== Load Model & Compute Class Weights =====================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path, num_labels=3)\n",
    "\n",
    "# Compute Class Weights for Imbalanced Data\n",
    "y_full_np = y_full.to_numpy()\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_full_np), y=y_full_np)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===================== Custom Trainer (Adds Weighted Loss & Confusion Matrix) =====================\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Custom loss function that applies class weights.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")  # Extract labels\n",
    "        outputs = model(**inputs)  # Forward pass\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Apply class weights\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Generate Predictions\n",
    "        predictions = self.predict(test_dataset)\n",
    "        y_pred = np.argmax(predictions.predictions, axis=1)  # Convert logits to predicted class\n",
    "        y_true = predictions.label_ids  # True labels\n",
    "\n",
    "        # Compute Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Plot Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Negative\", \"Neutral\", \"Positive\"],\n",
    "                    yticklabels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(f\"Confusion Matrix - Epoch {self.state.epoch}\")\n",
    "        plt.show()\n",
    "\n",
    "# ===================== Define Metrics Function =====================\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = logits.argmax(-1)  # Convert logits to predicted class labels\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "# ===================== Hyperparameter Search Function =====================\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(checkpoint_path, num_labels=3)\n",
    "\n",
    "# ===================== Train Model with Early Stopping, LR Scheduler & Hyperparameter Search =====================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./final_results\",\n",
    "    evaluation_strategy=\"steps\",  # Evaluate after a set number of steps instead of every epoch\n",
    "    save_strategy=\"steps\",  # Save model checkpoints at regular intervals\n",
    "    eval_steps=1000,  # Evaluate every 1000 steps (adjust based on dataset size)\n",
    "    save_steps=1000,  # Save checkpoints every 1000 steps\n",
    "    save_total_limit=3,  # Keep only the last 3 checkpoints to save storage\n",
    "    learning_rate=best_learning_rate,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./final_logs\",\n",
    "    logging_steps=500,  # Log loss and metrics every 500 steps\n",
    "    load_best_model_at_end=True,  # Ensures we use the best checkpoint\n",
    "    metric_for_best_model=\"f1\",  # Save the model that gives the best F1-score\n",
    "    greater_is_better=True,  # Higher F1-score is better\n",
    "    report_to=\"none\",  # Disable external tracking (e.g., WandB)\n",
    "    fp16=True,  # Use mixed precision for faster training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize final trainer\n",
    "final_trainer = CustomTrainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,  # Separate test dataset for evaluation\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Stops if no improvement for 2 evaluations\n",
    ")\n",
    "\n",
    "# Train on full dataset\n",
    "final_trainer.train()\n",
    "\n",
    "# Save final trained model\n",
    "model.save_pretrained(\"./final_biobert_model\")\n",
    "tokenizer.save_pretrained(\"./final_biobert_model\")\n",
    "\n",
    "# =====================  Run One Final Evaluation  =====================\n",
    "print(\"Final Evaluation on Full Training Set...\")\n",
    "evaluation_results = final_trainer.evaluate(eval_dataset=train_dataset)  # Manual evaluation\n",
    "print(\"Final Training Dataset Evaluation Results:\", evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
